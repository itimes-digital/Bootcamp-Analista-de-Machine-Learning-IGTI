{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "preparando_dataset_dados_textuais.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNnLjsZzk3IZTcaw2WPv3Ft",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/itimes-digital/Bootcamp-Analista-de-Machine-Learning-IGTI/blob/master/preparando_dataset_dados_textuais.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0qGaZrfH8j0v",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "b960163f-2301-4650-acb5-88a38744b270"
      },
      "source": [
        "import nltk\n",
        "import numpy as np\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')\n",
        "from pprint import pprint"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YnUiYcZLPjyu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 425
        },
        "outputId": "7fcac762-30a5-4f62-d9d1-aec3214a570a"
      },
      "source": [
        "stopWordPortugues = nltk.corpus.stopwords.words('portuguese')\n",
        "print(np.transpose(stopWordPortugues)) # transposição de coluna para linha a estruturra de dados"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['de' 'a' 'o' 'que' 'e' 'é' 'do' 'da' 'em' 'um' 'para' 'com' 'não' 'uma'\n",
            " 'os' 'no' 'se' 'na' 'por' 'mais' 'as' 'dos' 'como' 'mas' 'ao' 'ele' 'das'\n",
            " 'à' 'seu' 'sua' 'ou' 'quando' 'muito' 'nos' 'já' 'eu' 'também' 'só'\n",
            " 'pelo' 'pela' 'até' 'isso' 'ela' 'entre' 'depois' 'sem' 'mesmo' 'aos'\n",
            " 'seus' 'quem' 'nas' 'me' 'esse' 'eles' 'você' 'essa' 'num' 'nem' 'suas'\n",
            " 'meu' 'às' 'minha' 'numa' 'pelos' 'elas' 'qual' 'nós' 'lhe' 'deles'\n",
            " 'essas' 'esses' 'pelas' 'este' 'dele' 'tu' 'te' 'vocês' 'vos' 'lhes'\n",
            " 'meus' 'minhas' 'teu' 'tua' 'teus' 'tuas' 'nosso' 'nossa' 'nossos'\n",
            " 'nossas' 'dela' 'delas' 'esta' 'estes' 'estas' 'aquele' 'aquela'\n",
            " 'aqueles' 'aquelas' 'isto' 'aquilo' 'estou' 'está' 'estamos' 'estão'\n",
            " 'estive' 'esteve' 'estivemos' 'estiveram' 'estava' 'estávamos' 'estavam'\n",
            " 'estivera' 'estivéramos' 'esteja' 'estejamos' 'estejam' 'estivesse'\n",
            " 'estivéssemos' 'estivessem' 'estiver' 'estivermos' 'estiverem' 'hei' 'há'\n",
            " 'havemos' 'hão' 'houve' 'houvemos' 'houveram' 'houvera' 'houvéramos'\n",
            " 'haja' 'hajamos' 'hajam' 'houvesse' 'houvéssemos' 'houvessem' 'houver'\n",
            " 'houvermos' 'houverem' 'houverei' 'houverá' 'houveremos' 'houverão'\n",
            " 'houveria' 'houveríamos' 'houveriam' 'sou' 'somos' 'são' 'era' 'éramos'\n",
            " 'eram' 'fui' 'foi' 'fomos' 'foram' 'fora' 'fôramos' 'seja' 'sejamos'\n",
            " 'sejam' 'fosse' 'fôssemos' 'fossem' 'for' 'formos' 'forem' 'serei' 'será'\n",
            " 'seremos' 'serão' 'seria' 'seríamos' 'seriam' 'tenho' 'tem' 'temos' 'tém'\n",
            " 'tinha' 'tínhamos' 'tinham' 'tive' 'teve' 'tivemos' 'tiveram' 'tivera'\n",
            " 'tivéramos' 'tenha' 'tenhamos' 'tenham' 'tivesse' 'tivéssemos' 'tivessem'\n",
            " 'tiver' 'tivermos' 'tiverem' 'terei' 'terá' 'teremos' 'terão' 'teria'\n",
            " 'teríamos' 'teriam']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lez7rVTLP7uO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "66643025-f420-488d-a6c9-27430cb50967"
      },
      "source": [
        "sample_text = \"\"\" O menino gosta de jogar futebol aos finais de semana.\n",
        "Ele gosta de jogar com seus amigos Marco e João, mas gosta de brincar\n",
        "com a irmã Marcela\"\"\"\n",
        "\n",
        "# Por parágrafos/sentenças\n",
        "tokenizacao_sentencas = nltk.sent_tokenize\n",
        "sample_sentense = tokenizacao_sentencas(text=sample_text)\n",
        "pprint(sample_text)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(' O menino gosta de jogar futebol aos finais de semana.\\n'\n",
            " 'Ele gosta de jogar com seus amigos Marco e João, mas gosta de brincar\\n'\n",
            " 'com a irmã Marcela')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XAdf-tA8RVZn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "46525c27-0d95-417b-e396-996e865aca1a"
      },
      "source": [
        "len(sample_sentense)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QHvRAP9aRhY3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "92594e38-ebae-465f-bfbd-e98e60b658ea"
      },
      "source": [
        "sample_sentense = 'O menino gosta de jogar futebol aos finais de semana.'\n",
        "\n",
        "# Por palavras\n",
        "tokenizacao_palavras = nltk.word_tokenize\n",
        "sample_words = tokenizacao_palavras(text = sample_sentense)\n",
        "pprint(sample_words)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['O',\n",
            " 'menino',\n",
            " 'gosta',\n",
            " 'de',\n",
            " 'jogar',\n",
            " 'futebol',\n",
            " 'aos',\n",
            " 'finais',\n",
            " 'de',\n",
            " 'semana',\n",
            " '.']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-xeKSt6TR3IS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "001452fc-f607-43cb-c0a7-3291a04abdf0"
      },
      "source": [
        "from nltk.stem import PorterStemmer # stemização baseado no algoritmo de Porter\n",
        "from nltk.stem import RSLPStemmer # stemização para o português\n",
        "nltk.download('rslp')"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package rslp to /root/nltk_data...\n",
            "[nltk_data]   Unzipping stemmers/rslp.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y_UrjTxzSU_3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "b0b2635e-d7b6-49c7-8f97-69bbd7da5c34"
      },
      "source": [
        "ps = PorterStemmer()\n",
        "stemmer = RSLPStemmer()\n",
        "\n",
        "print(ps.stem('jumping'))\n",
        "print(stemmer.stem('amoroso'))\n",
        "print(stemmer.stem('amorosa'))\n",
        "print(stemmer.stem('amados'))\n",
        "print(stemmer.stem('amar'))"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "jump\n",
            "amor\n",
            "amor\n",
            "am\n",
            "am\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1KQ1Xs7p5jdw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "bc5498d5-6a0c-46e9-9e80-50cc1bab0fd0"
      },
      "source": [
        "from nltk.stem import SnowballStemmer # mais indicado para a outras linguagens\n",
        "\n",
        "print('Linguagens suportadas %s', SnowballStemmer.languages)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Linguagens suportadas %s ('arabic', 'danish', 'dutch', 'english', 'finnish', 'french', 'german', 'hungarian', 'italian', 'norwegian', 'porter', 'portuguese', 'romanian', 'russian', 'spanish', 'swedish')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l5aFKEE66JMq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "3d6f60e3-5944-435d-815f-600b59303ba9"
      },
      "source": [
        "ss = SnowballStemmer('portuguese')\n",
        "print(ss.stem('casado'))\n",
        "print(ss.stem('casarão'))\n",
        "print(ss.stem('casa'))\n",
        "print(ss.stem('casamenteiro'))\n",
        "print(ss.stem('casar'))"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cas\n",
            "cas\n",
            "cas\n",
            "casamenteir\n",
            "cas\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3g_WMt5A6ZIV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sentenca = 'O IGTI oferece especializacao em Deep Learning. Deep Learning e utilizado em diversas aplicacoes. As aplicacoes de deep learning sao estudadas nesta especializacao. O IGTI tambem oferece bootcamp'"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0HuLOvls7FYk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sentenca = sentenca.lower()"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YVpYJtBD7Lng",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "0b557f31-2d8f-488f-cab9-fb6c22027dfc"
      },
      "source": [
        "print(sentenca)"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "o igti oferece especializacao em deep learning. deep learning e utilizado em diversas aplicacoes. as aplicacoes de deep learning sao estudadas nesta especializacao. o igti tambem oferece bootcamp\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XpWpdmoW7Nlo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "197d590d-d30c-4398-a447-035fabc80e86"
      },
      "source": [
        "tokenizacao_sentencas = nltk.sent_tokenize\n",
        "sample_sentense = tokenizacao_sentencas(text=sentenca)\n",
        "pprint(sample_sentense)"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['o igti oferece especializacao em deep learning.',\n",
            " 'deep learning e utilizado em diversas aplicacoes.',\n",
            " 'as aplicacoes de deep learning sao estudadas nesta especializacao.',\n",
            " 'o igti tambem oferece bootcamp']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0mg2wlSr7dgu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "ac17a819-7764-452c-d95f-755b977e3735"
      },
      "source": [
        "sample_sentense[0]"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'o igti oferece especializacao em deep learning.'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j3CM1mKg7iYS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tokenizacao_palavras = nltk.word_tokenize\n",
        "list_words = []\n",
        "\n",
        "for i in range(len(sample_sentense)):\n",
        "  sample_words = tokenizacao_palavras(text=sample_sentense[i])\n",
        "  list_words.extend(sample_words)"
      ],
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "atBfOA_l79Lr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "d88e6f79-4694-49be-af73-2295b8c9a0ab"
      },
      "source": [
        "print(np.transpose(list_words))"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['o' 'igti' 'oferece' 'especializacao' 'em' 'deep' 'learning' '.' 'deep'\n",
            " 'learning' 'e' 'utilizado' 'em' 'diversas' 'aplicacoes' '.' 'as'\n",
            " 'aplicacoes' 'de' 'deep' 'learning' 'sao' 'estudadas' 'nesta'\n",
            " 'especializacao' '.' 'o' 'igti' 'tambem' 'oferece' 'bootcamp']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AUSUAbXz881H",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def tokenizaPalavras(sentenca):\n",
        "  sample_words = tokenizacao_palavras(text=sentenca)\n",
        "  return sample_words\n",
        "\n",
        "def removeStopWords(list_of_words):\n",
        "  my_top_words = ['o', 'em', 'as', 'de', 'sao', 'nesta', '.', 'e', 'a', 'na', 'do']\n",
        "  list_cleaned = set(list_of_words) - set(my_top_words)\n",
        "  return list_cleaned\n",
        "\n",
        "my_Bow = removeStopWords(list_words)"
      ],
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mlnrzXvX-kSb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "4f6b81f2-c23d-4649-fc20-d3bdea3c8979"
      },
      "source": [
        "print(my_Bow)"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'tambem', 'igti', 'diversas', 'aplicacoes', 'deep', 'bootcamp', 'utilizado', 'oferece', 'learning', 'especializacao', 'estudadas'}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cLfCuvj1-oGm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def bagofwords(sentence, words):\n",
        "  sentence_words = tokenizacao_palavras(sentence)\n",
        "  bag = np.zeros(len(words))\n",
        "  for sw in sentence_words:\n",
        "    for i,word in enumerate(words):\n",
        "      if word == sw:\n",
        "        bag[i] += 1\n",
        "  return np.array(bag)"
      ],
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bBOtjHwVBG09",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "02724cf5-f2bb-4e95-d8e9-558a92e3ed35"
      },
      "source": [
        "sentence_teste = 'o igti oferece especializacao em dee learning e o igti oferece bootcamp'\n",
        "print(bagofwords(sentence_teste, my_Bow))"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0. 2. 0. 0. 0. 1. 0. 2. 1. 1. 0.]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q4oX4_PQBi6_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}